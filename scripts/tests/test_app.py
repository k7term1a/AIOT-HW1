#!/usr/bin/env python3
"""
æ¸¬è©¦è…³æœ¬ï¼šé©—è­‰ç·šæ€§è¿´æ­¸ CRISP-DM æ‡‰ç”¨ç¨‹å¼çš„æ ¸å¿ƒåŠŸèƒ½
"""

import sys
import os
import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼å¾Œç«¯
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import train_test_split

def test_core_functionality():
    """æ¸¬è©¦æ ¸å¿ƒç·šæ€§è¿´æ­¸åŠŸèƒ½"""
    print("ğŸ§ª é–‹å§‹æ¸¬è©¦æ ¸å¿ƒåŠŸèƒ½...")
    
    # ç”Ÿæˆæ¸¬è©¦è³‡æ–™
    np.random.seed(42)
    a_value = 2.0
    b_value = 5.0
    noise_level = 1.0
    n_points = 100
    
    X = np.random.uniform(-10, 10, n_points)
    noise = np.random.normal(0, noise_level, n_points)
    y = a_value * X + b_value + noise
    
    print(f"âœ… è³‡æ–™ç”ŸæˆæˆåŠŸ: {n_points} å€‹è³‡æ–™é»")
    print(f"   çœŸå¯¦åƒæ•¸: a={a_value}, b={b_value}")
    print(f"   è³‡æ–™ç¯„åœ: X[{X.min():.2f}, {X.max():.2f}], y[{y.min():.2f}, {y.max():.2f}]")
    
    # å»ºç«‹ DataFrame
    df = pd.DataFrame({'X': X, 'y': y})
    print(f"âœ… DataFrame å»ºç«‹æˆåŠŸ: {df.shape}")
    
    # è¨ˆç®—ç›¸é—œæ€§
    correlation = np.corrcoef(X, y)[0, 1]
    print(f"âœ… ç›¸é—œä¿‚æ•¸è¨ˆç®—æˆåŠŸ: {correlation:.3f}")
    
    # è³‡æ–™åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X.reshape(-1, 1), y, test_size=0.2, random_state=42
    )
    print(f"âœ… è³‡æ–™åˆ†å‰²æˆåŠŸ: è¨“ç·´é›† {len(X_train)}, æ¸¬è©¦é›† {len(X_test)}")
    
    # å»ºç«‹å’Œè¨“ç·´æ¨¡å‹
    model = LinearRegression()
    model.fit(X_train, y_train)
    
    estimated_a = model.coef_[0]
    estimated_b = model.intercept_
    print(f"âœ… æ¨¡å‹è¨“ç·´æˆåŠŸ:")
    print(f"   ä¼°è¨ˆåƒæ•¸: a={estimated_a:.3f}, b={estimated_b:.3f}")
    print(f"   åƒæ•¸èª¤å·®: a_error={abs(estimated_a - a_value):.3f}, b_error={abs(estimated_b - b_value):.3f}")
    
    # é æ¸¬å’Œè©•ä¼°
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    r2_train = r2_score(y_train, y_train_pred)
    r2_test = r2_score(y_test, y_test_pred)
    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))
    rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred))
    
    print(f"âœ… æ¨¡å‹è©•ä¼°æˆåŠŸ:")
    print(f"   è¨“ç·´ RÂ²: {r2_train:.3f}, RMSE: {rmse_train:.3f}")
    print(f"   æ¸¬è©¦ RÂ²: {r2_test:.3f}, RMSE: {rmse_test:.3f}")
    
    # è¦–è¦ºåŒ–æ¸¬è©¦
    try:
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))
        
        # æ•£é»åœ–å’Œè¿´æ­¸ç·š
        ax1.scatter(X_train.flatten(), y_train, alpha=0.6, label='Training')
        ax1.scatter(X_test.flatten(), y_test, alpha=0.6, label='Test')
        X_line = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
        y_line_pred = model.predict(X_line)
        ax1.plot(X_line, y_line_pred, 'g-', linewidth=2, label='Fitted')
        ax1.set_title('Linear Regression Fit')
        ax1.legend()
        
        # æ®˜å·®åœ–
        residuals_test = y_test - y_test_pred
        ax2.scatter(y_test_pred, residuals_test, alpha=0.6)
        ax2.axhline(y=0, color='r', linestyle='--')
        ax2.set_title('Residuals Plot')
        
        # é æ¸¬ vs å¯¦éš›
        ax3.scatter(y_test, y_test_pred, alpha=0.6)
        min_val, max_val = min(y_test.min(), y_test_pred.min()), max(y_test.max(), y_test_pred.max())
        ax3.plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect fit')
        ax3.set_title('Predicted vs Actual')
        ax3.legend()
        
        # æ®˜å·®åˆ†ä½ˆ
        ax4.hist(residuals_test, bins=15, alpha=0.7)
        ax4.set_title('Residuals Distribution')
        
        plt.tight_layout()
        plt.savefig('test_plots.png', dpi=150, bbox_inches='tight')
        plt.close()
        
        print("âœ… è¦–è¦ºåŒ–æ¸¬è©¦æˆåŠŸ: åœ–è¡¨å·²ä¿å­˜ç‚º test_plots.png")
    
    except Exception as e:
        print(f"âš ï¸  è¦–è¦ºåŒ–æ¸¬è©¦è­¦å‘Š: {e}")
    
    # æ¸¬è©¦é æ¸¬åŠŸèƒ½
    test_x = 0.0
    predicted_y = model.predict([[test_x]])[0]
    true_y = a_value * test_x + b_value
    print(f"âœ… é æ¸¬åŠŸèƒ½æ¸¬è©¦æˆåŠŸ:")
    print(f"   è¼¸å…¥ X: {test_x}")
    print(f"   é æ¸¬ y: {predicted_y:.3f}")
    print(f"   çœŸå¯¦ y: {true_y:.3f}")
    
    return True

def test_streamlit_imports():
    """æ¸¬è©¦ Streamlit ç›¸é—œçš„å°å…¥"""
    print("\nğŸ“¦ æ¸¬è©¦å¥—ä»¶å°å…¥...")
    
    try:
        import streamlit as st
        print("âœ… Streamlit å°å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ Streamlit å°å…¥å¤±æ•—: {e}")
        return False
    
    try:
        import numpy as np
        import pandas as pd
        import matplotlib.pyplot as plt
        import seaborn as sns
        from sklearn.linear_model import LinearRegression
        from sklearn.metrics import r2_score, mean_squared_error
        from sklearn.model_selection import train_test_split
        print("âœ… æ‰€æœ‰å¿…è¦å¥—ä»¶å°å…¥æˆåŠŸ")
    except ImportError as e:
        print(f"âŒ å¥—ä»¶å°å…¥å¤±æ•—: {e}")
        return False
    
    return True

def main():
    """ä¸»è¦æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ¯ ç·šæ€§è¿´æ­¸ CRISP-DM æ‡‰ç”¨ç¨‹å¼åŠŸèƒ½æ¸¬è©¦")
    print("=" * 50)
    
    # æ¸¬è©¦å¥—ä»¶å°å…¥
    if not test_streamlit_imports():
        print("âŒ å¥—ä»¶å°å…¥æ¸¬è©¦å¤±æ•—")
        return False
    
    # æ¸¬è©¦æ ¸å¿ƒåŠŸèƒ½
    if not test_core_functionality():
        print("âŒ æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦å¤±æ•—")
        return False
    
    print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
    print("=" * 50)
    print("âœ… æ‡‰ç”¨ç¨‹å¼å·²æº–å‚™å¥½éƒ¨ç½²")
    print("ğŸŒ Streamlit æ‡‰ç”¨ç¨‹å¼ç¶²å€: http://localhost:8501")
    print("ğŸ“ å°ˆæ¡ˆå·²åŒ…å«å®Œæ•´çš„ CRISP-DM å¯¦ä½œ")
    print("ğŸ è™›æ“¬ç’°å¢ƒè¨­å®šå®Œæˆ")
    print("ğŸ³ Docker å®¹å™¨åŒ–æ”¯æ´å·²å°±ç·’")
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)